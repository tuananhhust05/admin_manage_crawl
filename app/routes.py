from flask import Blueprint, request, jsonify, current_app, render_template
from flask_pymongo import PyMongo
from bson import ObjectId
from datetime import datetime
import json
import os
import yt_dlp
import pysrt
import uuid
import logging
from typing import List, Dict, Any
import traceback
import time
import threading
# Import Elasticsearch service
from elasticsearch_service import elasticsearch_service

# Import Groq for article  generation
try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False
    logging.warning("Groq library not available. Article generation will be disabled.")

main = Blueprint('main', __name__)

def get_mongo():
    return PyMongo(current_app)

# Groq API helper functions
def get_groq_client():
    """Initialize Groq client with API key from environment"""
    if not GROQ_AVAILABLE:
        raise Exception("Groq library not available")
    
    groq_key = os.getenv('GROQ_KEY')
    if not groq_key:
        raise Exception("GROQ_KEY not found in environment variables")
    
    return Groq(api_key=groq_key)

def estimate_tokens(text: str) -> int:
    """Estimate tokens from text based on number of words."""
    TOKEN_RATIO = 0.75  # Approximate ratio between tokens and words
    return int(len(text.split()) / TOKEN_RATIO)

def truncate_articles(articles, max_input_tokens=5000):
    """Truncate combined articles to ensure input tokens <= max_input_tokens."""
    TOKEN_RATIO = 0.75
    words = []
    for article in articles:
        words.extend(article.split())

    max_words = int(max_input_tokens * TOKEN_RATIO)
    if len(words) <= max_words:
        return articles

    truncated_words = words[:max_words]
    truncated_text = " ".join(truncated_words)
    mid = len(truncated_text) // 2
    return [truncated_text[:mid], truncated_text[mid:]]

def extract_final_think_output(text: str) -> str:
    """
    Split by <think> and return the last segment (content after the final <think> tag).
    """
    parts = text.split("<think>")
    last_part = parts[-1]
    # Remove closing tag if exists
    if "</think>" in last_part:
        last_part = last_part.split("</think>")[-1]
    return last_part.strip()

def process_article_generation_async(fixture_id, related_requests, request_id):
    """
    X·ª≠ l√Ω t·∫°o b√†i vi·∫øt trong thread ri√™ng v·ªõi delay 20s
    """
    try:
        # Import mongo trong thread ƒë·ªÉ tr√°nh l·ªói
        from app import mongo
        logging.info(f"üöÄ Starting async article generation for fixture_id: {fixture_id}")
        logging.info(f"üìã Thread ID: {threading.current_thread().ident}")
        logging.info(f"‚è∞ Waiting 20 seconds before processing...")
        
        # Delay 20 seconds
        time.sleep(20)
        
        logging.info(f"‚è∞ 20s delay completed, starting article generation for fixture_id: {fixture_id}")
        
        # L·∫•y n·ªôi dung t·ª´ c√°c requests li√™n quan
        articles_data = []
        for req in related_requests:
            # L·∫•y n·ªôi dung t·ª´ c√°c field c√≥ th·ªÉ c√≥ v√† stringify
            content = None
            if 'content' in req:
                content = req['content']
            elif 'data' in req:
                content = req['data']
            elif 'body' in req:
                content = req['body']
            else:
                # N·∫øu kh√¥ng c√≥ field content, l·∫•y to√†n b·ªô request (tr·ª´ _id)
                req_copy = {k: v for k, v in req.items() if k != '_id'}
                content = json.dumps(req_copy, ensure_ascii=False, indent=2)
            
            if content:
                articles_data.append(content)
        
        logging.info(f"üìÑ Collected {len(articles_data)} articles for generation")
        
        if articles_data:
            logging.info(f"ü§ñ Generating article for fixture_id: {fixture_id} with {len(articles_data)} sources")
            
            # Generate article using Groq
            groq_result = generate_article_with_groq(articles_data)
            
            if groq_result['success']:
                # L∆∞u b√†i b√°o ƒë√£ generate v√†o collection generated_articles
                generated_article_doc = {
                    'fixture_id': fixture_id,
                    'title': f"Match Report - Fixture {fixture_id}",
                    'content': groq_result['article'],
                    'source_requests_count': len(related_requests),
                    'generated_at': datetime.utcnow(),
                    'created_at': datetime.utcnow(),
                    'request_id': request_id  # Link back to original request
                }
                
                article_result = mongo.db.generated_articles.insert_one(generated_article_doc)
                
                logging.info(f"‚úÖ Generated article saved with ID: {article_result.inserted_id}")
                
                # Update original request v·ªõi th√¥ng tin generated article
                mongo.db.requests.update_one(
                    {'_id': ObjectId(request_id)},
                    {
                        '$set': {
                            'generated_article_id': str(article_result.inserted_id),
                            'article_generated': True,
                            'article_generated_at': datetime.utcnow()
                        }
                    }
                )
                
                logging.info(f"‚úÖ Updated request {request_id} with generated article info")
                
            else:
                logging.error(f"‚ùå Failed to generate article: {groq_result.get('error', 'Unknown error')}")
                
                # Update original request v·ªõi error
                mongo.db.requests.update_one(
                    {'_id': ObjectId(request_id)},
                    {
                        '$set': {
                            'article_generated': False,
                            'generation_error': groq_result.get('error', 'Unknown error'),
                            'generation_failed_at': datetime.utcnow()
                        }
                    }
                )
        else:
            logging.warning(f"‚ö†Ô∏è No articles data found for fixture_id: {fixture_id}")
            
            # Update original request v·ªõi error
            mongo.db.requests.update_one(
                {'_id': ObjectId(request_id)},
                {
                    '$set': {
                        'article_generated': False,
                        'generation_error': 'No articles data found',
                        'generation_failed_at': datetime.utcnow()
                    }
                }
            )
            
    except Exception as e:
        logging.error(f"‚ùå Error in async article generation for fixture_id {fixture_id}: {str(e)}")
        logging.error(f"üìã Traceback: {traceback.format_exc()}")
        
        # Update original request v·ªõi error
        try:
            mongo.db.requests.update_one(
                {'_id': ObjectId(request_id)},
                {
                    '$set': {
                        'article_generated': False,
                        'generation_error': str(e),
                        'generation_failed_at': datetime.utcnow()
                    }
                }
            )
        except Exception as update_error:
            logging.error(f"‚ùå Failed to update request with error: {str(update_error)}")

def generate_article_with_groq(articles_data):
    """Generate article using Groq API"""
    try:
        client = get_groq_client()
        
        # Token constants
        MAX_OUTPUT_TOKENS = 3000
        MAX_INPUT_TOKENS = 5000
        
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ d·ªØ li·ªáu ƒë·ªÅu l√† string
        string_articles = []
        for article in articles_data:
            if isinstance(article, dict):
                string_articles.append(json.dumps(article, ensure_ascii=False, indent=2))
            else:
                string_articles.append(str(article))
        
        # Estimate token usage
        combined_text = "\n---\n".join(string_articles)
        estimated_input_tokens = estimate_tokens(combined_text)
        
        if estimated_input_tokens > MAX_INPUT_TOKENS:
            string_articles = truncate_articles(string_articles, MAX_INPUT_TOKENS)

        # Combine all articles
        combined_articles = "\n---\n".join(string_articles)
        
        logging.info(f"Combined articles length: {len(combined_articles)} characters")
        logging.info(f"Estimated tokens: {estimate_tokens(combined_articles)}")
        
        # Log input data for debugging
        logging.info("=" * 80)
        logging.info("GROQ API INPUT DEBUG:")
        logging.info(f"Number of articles: {len(string_articles)}")
        for i, article in enumerate(string_articles):
            logging.info(f"Article {i+1} (first 200 chars): {article[:200]}...")
        logging.info("=" * 80)

        # Prompt construction
        prompt = (
            "Using ONLY the information from the provided source articles, write a single, coherent, well-structured article in English. "
            "Do NOT include any reasoning, explanations, or thoughts. "
            "Do NOT add any information beyond the sources. "
            "Return ONLY the article text.\n\n"
            f"Source Articles:\n{combined_articles}"
        )
        
        # Log full prompt for debugging
        logging.info("=" * 80)
        logging.info("GROQ API PROMPT DEBUG:")
        logging.info(f"Prompt length: {len(prompt)} characters")
        logging.info(f"Full prompt:\n{prompt}")
        logging.info("=" * 80)

        response = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="groq/compound",
            max_tokens=MAX_OUTPUT_TOKENS,
        )

        generated_text = response.choices[0].message.content.strip()
        final_output = extract_final_think_output(generated_text)
        
        # Log response for debugging
        logging.info("=" * 80)
        logging.info("GROQ API RESPONSE DEBUG:")
        logging.info(f"Raw response length: {len(generated_text)} characters")
        logging.info(f"Raw response (first 500 chars): {generated_text[:500]}...")
        logging.info(f"Final output length: {len(final_output)} characters")
        logging.info(f"Final output (first 500 chars): {final_output[:500]}...")
        logging.info("=" * 80)
        
        return {
            'success': True,
            'article': final_output
        }
        
    except Exception as e:
        logging.error(f"Groq API error: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

def log_exception(function_name: str, error: Exception):
    """
    Helper function ƒë·ªÉ log exception ra terminal v·ªõi format ƒë·∫πp
    """
    print("=" * 60)
    print(f"ERROR in {function_name}:")
    print(f"Error: {str(error)}")
    print("Traceback:")
    traceback.print_exc()
    print("=" * 60)

def serialize_document(doc):
    """Convert MongoDB document to JSON serializable format"""
    if doc is None:
        return None
    
    # Create a copy to avoid modifying original document
    serialized_doc = {}
    
    for key, value in doc.items():
        if isinstance(value, ObjectId):
            # Convert ObjectId to string
            serialized_doc[key] = str(value)
        elif isinstance(value, datetime):
            # Convert datetime to ISO format
            serialized_doc[key] = value.isoformat()
        elif isinstance(value, dict):
            # Recursively serialize nested documents
            serialized_doc[key] = serialize_document(value)
        elif isinstance(value, list):
            # Handle lists that might contain ObjectIds or datetimes
            serialized_doc[key] = []
            for item in value:
                if isinstance(item, ObjectId):
                    serialized_doc[key].append(str(item))
                elif isinstance(item, datetime):
                    serialized_doc[key].append(item.isoformat())
                elif isinstance(item, dict):
                    serialized_doc[key].append(serialize_document(item))
                else:
                    serialized_doc[key].append(item)
        else:
            # Keep other values as is
            serialized_doc[key] = value
    
    return serialized_doc

def serialize_documents(docs):
    """Convert list of MongoDB documents to JSON serializable format"""
    return [serialize_document(doc) for doc in docs]

# Custom JSON encoder ƒë·ªÉ x·ª≠ l√Ω ObjectId
class JSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, ObjectId):
            return str(obj)
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super(JSONEncoder, self).default(obj)

# Trang ch·ªß
@main.route('/')
def home():
    print("Home")
    return jsonify({
        'message': 'Ch√†o m·ª´ng ƒë·∫øn v·ªõi PlayFantasy365 API',
        'version': '1.0.0',
        'endpoints': {
            'users': '/api/users',
            'games': '/api/games',
            'teams': '/api/teams',
            'youtube_channels': '/api/youtube-channels'
        }
    })

# YouTube Channels Management Page
@main.route('/youtube-channels')
def youtube_channels_page():
    return render_template('index.html')

@main.route('/search', methods=['GET'])
def search_page():
    """Render search page"""
    return render_template('search.html')

# Channel Detail Page
@main.route('/channel-detail')
def channel_detail_page():
    return render_template('channel_detail.html')

# Video Detail Page
@main.route('/video-detail')
def video_detail_page():
    return render_template('video_detail.html')

# Article Summarizer Page
@main.route('/article-summarizer', methods=['GET'])
def article_summarizer_page():
    return render_template('article_summarizer.html')

# Generated Articles Statistics Page
@main.route('/generated-articles', methods=['GET'])
def generated_articles_page():
    """Render the generated articles statistics page"""
    return render_template('generated_articles.html')

# Articles Page
@main.route('/articles', methods=['GET'])
def articles_page():
    """Render the articles page with type filtering"""
    try:
        mongo = get_mongo()
        
        # Get type filter from query parameter
        selected_type = request.args.get('type', 'fotmob')
        
        # Debug: Check what collections exist
        collections = mongo.db.list_collection_names()
        print(f"Available collections: {collections}")
        
        # Check if articles collection exists and has data
        articles_count = mongo.db.articles.count_documents({})
        print(f"Total articles in collection: {articles_count}")
        
        # Query articles with type filter, sorted by newest first
        query = {'type': selected_type} if selected_type != 'all' else {}
        articles = list(mongo.db.articles.find(query).sort('created_at', -1))
        
        print(f"Found {len(articles)} articles for type: {selected_type}")
        
        # Get unique types for the dropdown
        unique_types = mongo.db.articles.distinct('type')
        print(f"Available types: {unique_types}")
        
        # Convert ObjectId to string for JSON serialization
        for article in articles:
            article['_id'] = str(article['_id'])
            if 'created_at' in article:
                article['created_at'] = article['created_at'].isoformat() if hasattr(article['created_at'], 'isoformat') else str(article['created_at'])
        
        return render_template('articles.html', 
                             articles=articles, 
                             selected_type=selected_type,
                             available_types=unique_types)
        
    except Exception as e:
        log_exception("articles_page", e)
        return render_template('articles.html', 
                             articles=[], 
                             selected_type='fotmob',
                             available_types=['fotmob'],
                             error=str(e))

# Debug API for articles
@main.route('/api/debug-articles', methods=['GET'])
def debug_articles():
    """Debug API to check articles collection"""
    try:
        mongo = get_mongo()
        
        # Get all collections
        collections = mongo.db.list_collection_names()
        
        # Check articles collection
        articles_count = mongo.db.articles.count_documents({})
        
        # Get sample articles
        sample_articles = list(mongo.db.articles.find().limit(5))
        
        # Get unique types
        unique_types = mongo.db.articles.distinct('source')
        
        # Convert ObjectId to string
        for article in sample_articles:
            article['_id'] = str(article['_id'])
        
        return jsonify({
            'success': True,
            'collections': collections,
            'articles_count': articles_count,
            'unique_types': unique_types,
            'sample_articles': sample_articles
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# Create sample articles for testing
@main.route('/api/create-sample-articles', methods=['POST'])
def create_sample_articles():
    """Create sample articles for testing"""
    try:
        mongo = get_mongo()
        
        sample_articles = [
            {
                'title': 'FotMob: Premier League Transfer News',
                'content': 'Latest transfer updates from the Premier League including major signings and departures.',
                'summary': 'Comprehensive coverage of Premier League transfer activities with expert analysis.',
                'source': 'fotmob',
                'url': 'https://fotmob.com/news/premier-league-transfers',
                'created_at': datetime.utcnow()
            },
            {
                'title': 'FotMob: Champions League Predictions',
                'content': 'Expert predictions for the upcoming Champions League matches and potential winners.',
                'summary': 'In-depth analysis of Champions League teams and their chances of success.',
                'source': 'fotmob',
                'url': 'https://fotmob.com/news/champions-league-predictions',
                'created_at': datetime.utcnow()
            },
            {
                'title': 'FotMob: La Liga Weekend Review',
                'content': 'Complete review of the weekend matches in La Liga with highlights and analysis.',
                'summary': 'Comprehensive coverage of La Liga weekend action with key moments and statistics.',
                'source': 'fotmob',
                'url': 'https://fotmob.com/news/la-liga-weekend-review',
                'created_at': datetime.utcnow()
            },
            {
                'title': 'General Football News',
                'content': 'General football news and updates from around the world.',
                'summary': 'Latest football news covering various leagues and competitions worldwide.',
                'source': 'news',
                'url': 'https://example.com/football-news',
                'created_at': datetime.utcnow()
            }
        ]
        
        # Insert sample articles
        result = mongo.db.articles.insert_many(sample_articles)
        
        return jsonify({
            'success': True,
            'message': f'Created {len(result.inserted_ids)} sample articles',
            'inserted_ids': [str(id) for id in result.inserted_ids]
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# API to get articles for frontend
@main.route('/api/articles', methods=['GET'])
def get_articles():
    """API to get articles for frontend with search and filter support"""
    try:
        mongo = get_mongo()
        
        # Get parameters from query
        selected_type = request.args.get('type', 'fotmob')
        search_query = request.args.get('search', '').strip()
        
        # Build query
        query = {}
        
        # Add type filter
        if selected_type != 'all':
            query['source'] = selected_type
        
        # Add search filter
        if search_query:
            query['$or'] = [
                {'title': {'$regex': search_query, '$options': 'i'}},
                {'content': {'$regex': search_query, '$options': 'i'}},
                {'summary': {'$regex': search_query, '$options': 'i'}}
            ]
        
        # Query articles with filters, sorted by newest first
        articles = list(mongo.db.articles.find(query).sort('created_at', -1))
        
        # Get unique types for the dropdown
        unique_types = mongo.db.articles.distinct('source')
        
        # Convert ObjectId to string for JSON serialization
        for article in articles:
            article['_id'] = str(article['_id'])
            if 'created_at' in article:
                article['created_at'] = article['created_at'].isoformat() if hasattr(article['created_at'], 'isoformat') else str(article['created_at'])
        
        return jsonify({
            'success': True,
            'articles': articles,
            'selected_type': selected_type,
            'search_query': search_query,
            'available_types': unique_types,
            'total_count': len(articles)
        })
        
    except Exception as e:
        log_exception("get_articles", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# API to generate article from selected articles
@main.route('/api/generate-article', methods=['POST'])
def generate_article():
    """Generate article from selected articles"""
    try:
        data = request.get_json()
        articles = data.get('articles', [])
        
        if not articles:
            return jsonify({
                'success': False,
                'error': 'No articles provided'
            }), 400
        
        if len(articles) > 3:
            return jsonify({
                'success': False,
                'error': 'Maximum 3 articles allowed'
            }), 400
        
        # Call external API
        import requests
        external_api_url = 'http://46.62.152.241:5002/generate-article'
        
        payload = {
            'articles': articles
        }
        
        response = requests.post(external_api_url, json=payload)
        
        if response.status_code == 200:
            result = response.json()
            return jsonify({
                'success': True,
                'generated_article': result.get('generated_article', ''),
                'articles_count': len(articles)
            })
        else:
            return jsonify({
                'success': False,
                'error': f'External API error: {response.status_code}'
            }), 500
            
    except Exception as e:
        log_exception("generate_article", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# API Users
@main.route('/api/users', methods=['GET'])
def get_users():
    try:
        mongo = get_mongo()
        users = list(mongo.db.users.find())
        users = serialize_documents(users)
        return jsonify({
            'success': True,
            'data': users,
            'count': len(users)
        }), 200
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/users', methods=['POST'])
def create_user():
    try:
        data = request.get_json()
        
        # Validation c∆° b·∫£n
        if not data or 'username' not in data or 'email' not in data:
            return jsonify({
                'success': False,
                'error': 'Username v√† email l√† b·∫Øt bu·ªôc'
            }), 400
        
        mongo = get_mongo()
        # Ki·ªÉm tra user ƒë√£ t·ªìn t·∫°i
        existing_user = mongo.db.users.find_one({'email': data['email']})
        if existing_user:
            return jsonify({
                'success': False,
                'error': 'Email ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng'
            }), 400
        
        # T·∫°o user m·ªõi
        user_data = {
            'username': data['username'],
            'email': data['email'],
            'created_at': datetime.utcnow(),
            'updated_at': datetime.utcnow()
        }
        
        # Th√™m c√°c field optional
        if 'full_name' in data:
            user_data['full_name'] = data['full_name']
        if 'phone' in data:
            user_data['phone'] = data['phone']
        
        result = mongo.db.users.insert_one(user_data)
        
        return jsonify({
            'success': True,
            'message': 'User ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng',
            'user_id': str(result.inserted_id)
        }), 201
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/users/<user_id>', methods=['GET'])
def get_user(user_id):
    try:
        mongo = get_mongo()
        user = mongo.db.users.find_one({'_id': ObjectId(user_id)})
        if not user:
            return jsonify({
                'success': False,
                'error': 'User not found'
            }), 404
        
        user = serialize_document(user)
        return jsonify({
            'success': True,
            'data': user
        }), 200
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# API Games
@main.route('/api/games', methods=['GET'])
def get_games():
    try:
        mongo = get_mongo()
        games = list(mongo.db.games.find())
        games = serialize_documents(games)
        return jsonify({
            'success': True,
            'data': games,
            'count': len(games)
        }), 200
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/games', methods=['POST'])
def create_game():
    try:
        data = request.get_json()
        
        if not data or 'name' not in data or 'sport' not in data:
            return jsonify({
                'success': False,
                'error': 'T√™n game v√† m√¥n th·ªÉ thao l√† b·∫Øt bu·ªôc'
            }), 400
        
        game_data = {
            'name': data['name'],
            'sport': data['sport'],
            'status': data.get('status', 'upcoming'),
            'created_at': datetime.utcnow(),
            'updated_at': datetime.utcnow()
        }
        
        if 'description' in data:
            game_data['description'] = data['description']
        if 'start_time' in data:
            game_data['start_time'] = data['start_time']
        if 'end_time' in data:
            game_data['end_time'] = data['end_time']
        
        mongo = get_mongo()
        result = mongo.db.games.insert_one(game_data)
        
        return jsonify({
            'success': True,
            'message': 'Game ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng',
            'game_id': str(result.inserted_id)
        }), 201
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# API Teams
@main.route('/api/teams', methods=['GET'])
def get_teams():
    try:
        mongo = get_mongo()
        teams = list(mongo.db.teams.find())
        teams = serialize_documents(teams)
        return jsonify({
            'success': True,
            'data': teams,
            'count': len(teams)
        }), 200
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/teams', methods=['POST'])
def create_team():
    try:
        data = request.get_json()
        
        if not data or 'name' not in data:
            return jsonify({
                'success': False,
                'error': 'T√™n team l√† b·∫Øt bu·ªôc'
            }), 400
        
        team_data = {
            'name': data['name'],
            'created_at': datetime.utcnow(),
            'updated_at': datetime.utcnow()
        }
        
        if 'description' in data:
            team_data['description'] = data['description']
        if 'sport' in data:
            team_data['sport'] = data['sport']
        if 'players' in data:
            team_data['players'] = data['players']
        
        mongo = get_mongo()
        result = mongo.db.teams.insert_one(team_data)
        
        return jsonify({
            'success': True,
            'message': 'Team ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng',
            'team_id': str(result.inserted_id)
        }), 201
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# API YouTube Channels
@main.route('/api/youtube-channels', methods=['GET'])
def get_youtube_channels():
    try:
        mongo = get_mongo()
        channels = list(mongo.db.youtube_channels.find().sort('created_at', -1))
        
        # Th√™m ƒë·∫øm s·ªë video cho m·ªói channel
        for channel in channels:
            video_count = mongo.db.videos.count_documents({'channel_id': channel['channel_id']})
            channel['video_count'] = video_count
        
        # Convert to JSON serializable format
        channels = serialize_documents(channels)
        
        return jsonify({
            'success': True,
            'data': channels,
            'count': len(channels)
        }), 200
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/youtube-channels', methods=['POST'])
def create_youtube_channel():
    try:
        data = request.get_json()
        
        if not data or 'url' not in data or 'channel_id' not in data:
            return jsonify({
                'success': False,
                'error': 'URL v√† Channel ID l√† b·∫Øt bu·ªôc'
            }), 400
        
        mongo = get_mongo()
        # Ki·ªÉm tra channel ƒë√£ t·ªìn t·∫°i
        existing_channel = mongo.db.youtube_channels.find_one({'channel_id': data['channel_id']})
        if existing_channel:
            return jsonify({
                'success': False,
                'error': 'Channel ID ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng'
            }), 400
        
        # T·∫°o channel m·ªõi
        channel_data = {
            'url': data['url'],
            'channel_id': data['channel_id'],
            'title': data.get('title', ''),
            'description': data.get('description', ''),
            'subscriber_count': data.get('subscriber_count', 0),
            'video_count': data.get('video_count', 0),
            'created_at': datetime.utcnow(),
            'updated_at': datetime.utcnow()
        }
        
        result = mongo.db.youtube_channels.insert_one(channel_data)
        
        return jsonify({
            'success': True,
            'message': 'YouTube channel ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng',
            'channel_id': str(result.inserted_id)
        }), 201
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/youtube-channels/<channel_id>', methods=['GET'])
def get_youtube_channel(channel_id):
    try:
        mongo = get_mongo()
        channel = mongo.db.youtube_channels.find_one({'_id': ObjectId(channel_id)})
        if not channel:
            return jsonify({
                'success': False,
                'error': 'YouTube channel not found'
            }), 404
        
        # Th√™m ƒë·∫øm s·ªë video cho channel
        video_count = mongo.db.videos.count_documents({'channel_id': channel['channel_id']})
        channel['video_count'] = video_count
        
        # Convert to JSON serializable format
        channel = serialize_document(channel)
        
        return jsonify({
            'success': True,
            'data': channel
        }), 200
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/youtube-channels/<channel_id>', methods=['PUT'])
def update_youtube_channel(channel_id):
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'D·ªØ li·ªáu c·∫≠p nh·∫≠t l√† b·∫Øt bu·ªôc'
            }), 400
        
        # C·∫≠p nh·∫≠t th·ªùi gian
        data['updated_at'] = datetime.utcnow()
        
        mongo = get_mongo()
        result = mongo.db.youtube_channels.update_one(
            {'_id': ObjectId(channel_id)},
            {'$set': data}
        )
        
        if result.matched_count == 0:
            return jsonify({
                'success': False,
                'error': 'YouTube channel kh√¥ng t·ªìn t·∫°i'
            }), 404
        
        return jsonify({
            'success': True,
            'message': 'YouTube channel ƒë∆∞·ª£c c·∫≠p nh·∫≠t th√†nh c√¥ng'
        }), 200
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/youtube-channels/<channel_id>', methods=['DELETE'])
def delete_youtube_channel(channel_id):
    try:
        mongo = get_mongo()
        result = mongo.db.youtube_channels.delete_one({'_id': ObjectId(channel_id)})
        
        if result.deleted_count == 0:
            return jsonify({
                'success': False,
                'error': 'YouTube channel kh√¥ng t·ªìn t·∫°i'
            }), 404
        
        return jsonify({
            'success': True,
            'message': 'YouTube channel ƒë∆∞·ª£c x√≥a th√†nh c√¥ng'
        }), 200
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# API Videos
@main.route('/api/videos', methods=['GET'])
def get_videos():
    try:
        mongo = get_mongo()
        channel_id = request.args.get('channel_id')
        
        query = {}
        if channel_id:
            query['channel_id'] = channel_id
        
        videos = list(mongo.db.videos.find(query).sort('published_at', -1))
        videos = serialize_documents(videos)
        
        return jsonify({
            'success': True,
            'data': videos,
            'count': len(videos)
        }), 200
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/videos/<video_id>', methods=['DELETE'])
def delete_video(video_id):
    try:
        mongo = get_mongo()
        result = mongo.db.videos.delete_one({'_id': ObjectId(video_id)})
        
        if result.deleted_count == 0:
            return jsonify({
                'success': False,
                'error': 'Video not found'
            }), 404
        
        return jsonify({
            'success': True,
            'message': 'Video deleted successfully'
        }), 200
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# Test endpoint
@main.route('/api/test', methods=['GET'])
def test_endpoint():
    return jsonify({
        'success': True,
        'message': 'API is working',
        'timestamp': datetime.utcnow().isoformat()
    }), 200

# Debug endpoint - list all routes
@main.route('/api/debug/routes', methods=['GET'])
def debug_routes():
    from flask import current_app
    routes = []
    for rule in current_app.url_map.iter_rules():
        routes.append({
            'endpoint': rule.endpoint,
            'methods': list(rule.methods),
            'rule': str(rule)
        })
    return jsonify({
        'success': True,
        'routes': routes
    }), 200

# Proxy API to external summarize service
@main.route('/api/summarize-articles', methods=['POST'])
def summarize_articles():
    try:
        data = request.get_json() or {}
        articles = data.get('articles', [])
        if not isinstance(articles, list) or len(articles) == 0:
            return jsonify({'success': False, 'error': 'articles must be a non-empty list'}), 400

        import requests
        resp = requests.post(
            'http://46.62.152.241:8000/synthesize',
            json={'articles': articles},
            headers={'Content-Type': 'application/json'}
        )
        if resp.status_code == 200:
            payload = resp.json()
            return jsonify({'success': True, 'data': payload}), 200
        return jsonify({'success': False, 'error': f'external service {resp.status_code}'}), 502
    except Exception as e:
        logging.exception('summarize_articles failed')
        return jsonify({'success': False, 'error': str(e)}), 500

# Search Documents API
@main.route('/api/search-documents', methods=['POST'])
def search_documents():
    """Search documents using external search service"""
    try:
        data = request.get_json()
        
        # Validate required fields
        if not data or 'keyword' not in data:
            return jsonify({
                'success': False,
                'error': 'Keyword is required'
            }), 400
        
        # Prepare search request
        search_request = {
            'keyword': data['keyword'],
            'limit': data.get('limit', 10),
            'min_score': data.get('min_score', 0.6),
            'include_content': data.get('include_content', True),
            'boost_recent': data.get('boost_recent', True)
        }
        
        # Call external search service
        import requests
        search_url = 'http://37.27.181.54:5009/search/relevant/advanced'
        
        response = requests.post(
            search_url,
            json=search_request,
            headers={'Content-Type': 'application/json'},
            timeout=30
        )
        
        if response.status_code == 200:
            search_data = response.json()
            return jsonify({
                'success': True,
                'data': search_data
            })
        else:
            return jsonify({
                'success': False,
                'error': f'Search service returned status {response.status_code}'
            }), 500
            
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'Search request timed out'
        }), 408
    except requests.exceptions.ConnectionError:
        return jsonify({
            'success': False,
            'error': 'Unable to connect to search service'
        }), 503
    except Exception as e:
        print(f"Search error: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error during search'
        }), 500

# Crawl Videos API
@main.route('/api/crawl-videos', methods=['POST'])
def crawl_videos():
    try:
        data = request.get_json()
        channel_id = data.get('channel_id')
        
        if not channel_id:
            return jsonify({
                'success': False,
                'error': 'Channel ID is required'
            }), 400
        
        # YouTube API configuration
        API_KEY = os.getenv('YOUTUBE_API_KEY')
        if not API_KEY:
            return jsonify({
                'success': False,
                'error': 'YouTube API key not configured. Please set YOUTUBE_API_KEY environment variable.'
            }), 500
        
        try:
            from googleapiclient.discovery import build
            youtube = build('youtube', 'v3', developerKey=API_KEY)
        except ImportError as e:
            return jsonify({
                'success': False,
                'error': f'Google API client not installed: {str(e)}'
            }), 500
        
        mongo = get_mongo()
        
        # Get channel's uploads playlist
        channel_request = youtube.channels().list(
            part='contentDetails',
            id=channel_id
        )
        channel_response = channel_request.execute()
        
        if 'items' not in channel_response or not channel_response['items']:
            return jsonify({
                'success': False,
                'error': 'Channel not found'
            }), 404
        
        playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
        
        # Get latest 10 videos
        videos = []
        next_page_token = None
        max_results = 10
        
        while len(videos) < max_results:
            playlist_request = youtube.playlistItems().list(
                part='snippet',
                playlistId=playlist_id,
                maxResults=min(50, max_results - len(videos)),
                pageToken=next_page_token
            )
            playlist_response = playlist_request.execute()
            
            for item in playlist_response['items']:
                if len(videos) >= max_results:
                    break
                    
                video_title = item['snippet']['title']
                video_id = item['snippet']['resourceId']['videoId']
                video_url = f'https://www.youtube.com/watch?v={video_id}'
                published_at = item['snippet']['publishedAt']
                description = item['snippet'].get('description', '')
                thumbnail_url = item['snippet']['thumbnails'].get('high', {}).get('url', '')
                
                # Get additional video details
                try:
                    video_request = youtube.videos().list(
                        part='statistics,contentDetails',
                        id=video_id
                    )
                    video_response = video_request.execute()
                    
                    if video_response['items']:
                        video_data = video_response['items'][0]
                        view_count = int(video_data['statistics'].get('viewCount', 0))
                        like_count = int(video_data['statistics'].get('likeCount', 0))
                        duration = video_data['contentDetails'].get('duration', '')
                    else:
                        view_count = 0
                        like_count = 0
                        duration = ''
                except:
                    view_count = 0
                    like_count = 0
                    duration = ''
                
                videos.append({
                    'title': video_title,
                    'url': video_url,
                    'video_id': video_id,
                    'description': description,
                    'thumbnail_url': thumbnail_url,
                    'view_count': view_count,
                    'like_count': like_count,
                    'duration': duration,
                    'published_at': datetime.fromisoformat(published_at.replace('Z', '+00:00'))
                })
            
            next_page_token = playlist_response.get('nextPageToken')
            if not next_page_token:
                break
        
        # Save videos to database
        crawled_count = 0
        for video_data in videos:
            # Check if video already exists
            existing_video = mongo.db.videos.find_one({'url': video_data['url']})
            if existing_video:
                continue
            
            # Create video document
            video_doc = {
                'url': video_data['url'],
                'channel_id': channel_id,
                'title': video_data['title'],
                'description': video_data['description'],
                'video_id': video_data['video_id'],
                'thumbnail_url': video_data['thumbnail_url'],
                'duration': video_data['duration'],
                'view_count': video_data['view_count'],
                'like_count': video_data['like_count'],
                'published_at': video_data['published_at'],
                'status': 0,  # pending
                'created_at': datetime.utcnow(),
                'updated_at': datetime.utcnow()
            }
            
            mongo.db.videos.insert_one(video_doc)
            crawled_count += 1
        
        return jsonify({
            'success': True,
            'message': f'Successfully crawled {crawled_count} new videos',
            'crawled_count': crawled_count,
            'total_found': len(videos)
        }), 200
        
    except Exception as e:
        log_exception("crawl_videos", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# Health check endpoint
@main.route('/health')
def health_check():
    try:
        # Ki·ªÉm tra k·∫øt n·ªëi MongoDB
        mongo = get_mongo()
        mongo.db.command('ping')
        return jsonify({
            'status': 'healthy',
            'database': 'connected',
            'timestamp': datetime.utcnow().isoformat()
        }), 200
    except Exception as e:
        return jsonify({
            'status': 'unhealthy',
            'database': 'disconnected',
            'error': str(e),
            'timestamp': datetime.utcnow().isoformat()
        }), 500

# ==============================================================================
# SRT PROCESSING FUNCTIONS
# ==============================================================================

def process_srt_file(srt_file_path: str, max_words: int = 350) -> List[Dict[str, Any]]:
    """
    ƒê·ªçc file SRT v√† chia th√†nh c√°c chunk v·ªõi gi·ªõi h·∫°n s·ªë t·ª´
    """
    try:
        subs = pysrt.open(srt_file_path, encoding='utf-8')
    except Exception as e:
        logging.error(f"L·ªói khi ƒë·ªçc file {srt_file_path}: {e}")
        return []

    chunks_data: List[Dict[str, Any]] = []
    current_chunk_captions: List[pysrt.SubRipItem] = []
    current_word_count = 0

    # Logic chunking th√¥ng minh
    for caption in subs:
        caption_text = caption.text.replace('\n', ' ')
        caption_word_count = len(caption_text.split())

        # Tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát: m·ªôt caption d√†i h∆°n gi·ªõi h·∫°n
        if caption_word_count > max_words:
            if current_chunk_captions:
                # Ho√†n th√†nh chunk hi·ªán t·∫°i tr∆∞·ªõc
                full_chunk_text = " ".join([c.text.replace('\n', ' ') for c in current_chunk_captions])
                start_time = str(current_chunk_captions[0].start)
                chunks_data.append({'text': full_chunk_text, 'time': start_time})
                current_chunk_captions = []
                current_word_count = 0

            # Chia nh·ªè caption qu√° d√†i
            words = caption_text.split()
            for i in range(0, len(words), max_words):
                sub_chunk_words = words[i : i + max_words]
                chunks_data.append({'text': " ".join(sub_chunk_words), 'time': str(caption.start)})
            continue

        # N·∫øu th√™m caption n√†y s·∫Ω v∆∞·ª£t qu√° gi·ªõi h·∫°n -> ho√†n th√†nh chunk hi·ªán t·∫°i
        if current_word_count + caption_word_count > max_words and current_chunk_captions:
            full_chunk_text = " ".join([c.text.replace('\n', ' ') for c in current_chunk_captions])
            start_time = str(current_chunk_captions[0].start)
            chunks_data.append({'text': full_chunk_text, 'time': start_time})
            
            # B·∫Øt ƒë·∫ßu chunk m·ªõi v·ªõi caption hi·ªán t·∫°i
            current_chunk_captions = [caption]
            current_word_count = caption_word_count
        else:
            # Ti·∫øp t·ª•c th√™m v√†o chunk hi·ªán t·∫°i
            current_chunk_captions.append(caption)
            current_word_count += caption_word_count

    # ƒê·ª´ng qu√™n chunk cu·ªëi c√πng
    if current_chunk_captions:
        full_chunk_text = " ".join([c.text.replace('\n', ' ') for c in current_chunk_captions])
        start_time = str(current_chunk_captions[0].start)
        chunks_data.append({'text': full_chunk_text, 'time': start_time})

    return chunks_data

def generate_unique_filename(video_url: str, extension: str = 'srt') -> str:
    """
    T·∫°o t√™n file unique d·ª±a tr√™n video URL
    """
    # Extract video ID from URL
    video_id = video_url.split('v=')[-1].split('&')[0] if 'v=' in video_url else str(uuid.uuid4())
    unique_id = str(uuid.uuid4())[:8]
    return f"{video_id}_{unique_id}.{extension}"

# ==============================================================================
# CRAWL SRT API ENDPOINTS
# ==============================================================================

@main.route('/api/crawl-srt', methods=['POST'])
def crawl_srt():
    """
    API ƒë·ªÉ crawl SRT t·ª´ video YouTube
    """
    try:
        data = request.get_json()
        video_url = data.get('video_url')
        
        if not video_url:
            return jsonify({
                'success': False,
                'error': 'Video URL is required'
            }), 400
        
        # T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ SRT n·∫øu ch∆∞a t·ªìn t·∫°i
        srt_folder = 'srt_files'
        if not os.path.exists(srt_folder):
            os.makedirs(srt_folder)
        
        # T·∫°o t√™n file unique
        srt_filename = generate_unique_filename(video_url)
        srt_file_path = os.path.join(srt_folder, srt_filename)
        
        # C·∫•u h√¨nh yt-dlp ƒë·ªÉ download subtitle
        ydl_opts = {
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': ['en'],  # Th·ª≠ c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát
            'subtitlesformat': 'srt',
            'skip_download': True,
            'outtmpl': srt_file_path.replace('.srt', '.%(ext)s'),
        }
        
        success = False
        error_message = ""
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([video_url])
                
                # Ki·ªÉm tra file ƒë√£ ƒë∆∞·ª£c t·∫°o
                if os.path.exists(srt_file_path):
                    success = True
                else:
                    # Th·ª≠ t√¨m file v·ªõi extension kh√°c
                    for ext in ['srt', 'vtt']:
                        test_path = srt_file_path.replace('.srt', f'.{ext}')
                        if os.path.exists(test_path):
                            os.rename(test_path, srt_file_path)
                            success = True
                            break
                            
        except Exception as e:
            error_message = str(e)
            logging.error(f"L·ªói khi download subtitle: {e}")
        
        if success:
            # L∆∞u th√¥ng tin v√†o database
            mongo = get_mongo()
            srt_doc = {
                'video_url': video_url,
                'srt_file_path': srt_file_path,
                'srt_filename': srt_filename,
                'status': 0,  # 0: pending processing
                'created_at': datetime.utcnow(),
                'updated_at': datetime.utcnow()
            }
            
            result = mongo.db.srt_files.insert_one(srt_doc)
            
            return jsonify({
                'success': True,
                'message': 'SRT file downloaded successfully',
                'srt_id': str(result.inserted_id),
                'srt_filename': srt_filename,
                'srt_file_path': srt_file_path
            }), 200
        else:
            return jsonify({
                'success': False,
                'error': f'Failed to download subtitle: {error_message}'
            }), 500
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/process-srt', methods=['POST'])
def process_srt():
    """
    API ƒë·ªÉ x·ª≠ l√Ω file SRT ƒë√£ crawl v√† l∆∞u chunks v√†o MongoDB
    """
    try:
        data = request.get_json()
        srt_id = data.get('srt_id')
        
        if not srt_id:
            return jsonify({
                'success': False,
                'error': 'SRT ID is required'
            }), 400
        
        mongo = get_mongo()
        
        # L·∫•y th√¥ng tin SRT file t·ª´ database
        srt_doc = mongo.db.srt_files.find_one({'_id': ObjectId(srt_id)})
        if not srt_doc:
            return jsonify({
                'success': False,
                'error': 'SRT file not found'
            }), 404
        
        srt_file_path = srt_doc['srt_file_path']
        
        # Ki·ªÉm tra file t·ªìn t·∫°i
        if not os.path.exists(srt_file_path):
            return jsonify({
                'success': False,
                'error': 'SRT file not found on disk'
            }), 404
        
        # X·ª≠ l√Ω file SRT
        chunks_data = process_srt_file(srt_file_path)
        
        if not chunks_data:
            return jsonify({
                'success': False,
                'error': 'No chunks extracted from SRT file'
            }), 500
        
        # L∆∞u chunks v√†o MongoDB
        chunks_docs = []
        for i, chunk_info in enumerate(chunks_data):
            chunk_doc = {
                'srt_id': ObjectId(srt_id),
                'video_url': srt_doc['video_url'],
                'chunk_index': i,
                'text': chunk_info['text'],
                'time': chunk_info['time'],
                'created_at': datetime.utcnow()
            }
            chunks_docs.append(chunk_doc)
        
        # Insert t·∫•t c·∫£ chunks
        if chunks_docs:
            mongo.db.srt_chunks.insert_many(chunks_docs)
        
        # C·∫≠p nh·∫≠t status c·ªßa SRT file
        mongo.db.srt_files.update_one(
            {'_id': ObjectId(srt_id)},
            {
                '$set': {
                    'status': 1,  # 1: processed
                    'chunks_count': len(chunks_data),
                    'updated_at': datetime.utcnow()
                }
            }
        )
        
        return jsonify({
            'success': True,
            'message': f'Successfully processed SRT file with {len(chunks_data)} chunks',
            'chunks_count': len(chunks_data),
            'chunks': chunks_data[:5]  # Tr·∫£ v·ªÅ 5 chunks ƒë·∫ßu ƒë·ªÉ preview
        }), 200
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/srt-files', methods=['GET'])
def get_srt_files():
    """
    API ƒë·ªÉ l·∫•y danh s√°ch SRT files
    """
    try:
        mongo = get_mongo()
        srt_files = list(mongo.db.srt_files.find().sort('created_at', -1))
        srt_files = serialize_documents(srt_files)
        
        return jsonify({
            'success': True,
            'data': srt_files,
            'count': len(srt_files)
        }), 200
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/srt-chunks/<srt_id>', methods=['GET'])
def get_srt_chunks(srt_id):
    """
    API ƒë·ªÉ l·∫•y chunks c·ªßa m·ªôt SRT file
    """
    try:
        mongo = get_mongo()
        chunks = list(mongo.db.srt_chunks.find({'srt_id': ObjectId(srt_id)}).sort('chunk_index', 1))
        chunks = serialize_documents(chunks)
        
        return jsonify({
            'success': True,
            'data': chunks,
            'count': len(chunks)
        }), 200
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==============================================================================
# VIDEO DETAILS AND TRANSCRIPTION API
# ==============================================================================

@main.route('/api/videos/<video_id>', methods=['GET'])
def get_video_details(video_id):
    """
    API ƒë·ªÉ l·∫•y chi ti·∫øt video v√† transcription
    """
    try:
        mongo = get_mongo()
        
        # L·∫•y th√¥ng tin video
        video = mongo.db.videos.find_one({'_id': ObjectId(video_id)})
        if not video:
            return jsonify({
                'success': False,
                'error': 'Video not found'
            }), 404
        
        # L·∫•y SRT files li√™n quan ƒë·∫øn video n√†y
        srt_files = list(mongo.db.srt_files.find({'video_url': video['url']}).sort('created_at', -1))
        
        # L·∫•y chunks c·ªßa SRT files ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        chunks_data = []
        for srt_file in srt_files:
            if srt_file.get('status') == 1:  # Ch·ªâ l·∫•y SRT ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
                # S·ª≠ d·ª•ng ObjectId t·ª´ srt_file (ch∆∞a ƒë∆∞·ª£c serialize)
                srt_object_id = srt_file['_id'] if isinstance(srt_file['_id'], ObjectId) else ObjectId(srt_file['_id'])
                chunks = list(mongo.db.srt_chunks.find({'srt_id': srt_object_id}).sort('chunk_index', 1))
                chunks_data.extend(chunks)
        
        # Serialize data
        video = serialize_document(video)
        srt_files = serialize_documents(srt_files)
        chunks_data = serialize_documents(chunks_data)
        
        return jsonify({
            'success': True,
            'data': {
                'video': video,
                'srt_files': srt_files,
                'chunks': chunks_data,
                'chunks_count': len(chunks_data)
            }
        }), 200
        
    except Exception as e:
        log_exception("get_video_details", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/crawl-video-srt', methods=['POST'])
def crawl_video_srt():
    """
    API ƒë·ªÉ crawl SRT cho m·ªôt video c·ª• th·ªÉ
    """
    try:
        data = request.get_json()
        video_id = data.get('video_id')
        
        if not video_id:
            return jsonify({
                'success': False,
                'error': 'Video ID is required'
            }), 400
        
        mongo = get_mongo()
        
        # L·∫•y th√¥ng tin video
        video = mongo.db.videos.find_one({'_id': ObjectId(video_id)})
        if not video:
            return jsonify({
                'success': False,
                'error': 'Video not found'
            }), 404
        
        video_url = video['url']
        print("url video: ", video_url)
        # Ki·ªÉm tra xem ƒë√£ c√≥ SRT file ch∆∞a
        existing_srt = mongo.db.srt_files.find_one({'video_url': video_url})
        if existing_srt:
            return jsonify({
                'success': False,
                'error': 'SRT file already exists for this video',
                'srt_id': str(existing_srt['_id'])
            }), 400
        
        # T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ SRT n·∫øu ch∆∞a t·ªìn t·∫°i
        srt_folder = 'srt_files'
        if not os.path.exists(srt_folder):
            os.makedirs(srt_folder)
        
        # T·∫°o t√™n file unique
        srt_filename = generate_unique_filename(video_url)
        srt_file_path = os.path.join(srt_folder, srt_filename)
        
        # C·∫•u h√¨nh yt-dlp ƒë·ªÉ download subtitle
        ydl_opts = {
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': ['en'],  # Th·ª≠ c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát
            'subtitlesformat': 'srt',
            'skip_download': True,
            'outtmpl': srt_file_path.replace('.srt', '.%(ext)s'),
        }
        
        success = False
        error_message = ""
        actual_srt_file = None
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([video_url])
                
                # T√¨m file SRT th·ª±c t·∫ø ƒë∆∞·ª£c t·∫°o (yt-dlp c√≥ th·ªÉ t·∫°o t√™n kh√°c)
                actual_srt_file = None
                
                # Ki·ªÉm tra file v·ªõi t√™n mong ƒë·ª£i tr∆∞·ªõc
                if os.path.exists(srt_file_path):
                    actual_srt_file = srt_file_path
                    success = True
                else:
                    # Extract video ID t·ª´ URL ƒë·ªÉ t√¨m file
                    video_id_from_url = video_url.split('v=')[-1].split('&')[0] if 'v=' in video_url else ''
                    
                    # T√¨m t·∫•t c·∫£ file .srt trong th∆∞ m·ª•c
                    for file in os.listdir(srt_folder):
                        if file.endswith('.srt') and video_id_from_url in file:  # Video ID trong t√™n file
                            actual_srt_file = os.path.join(srt_folder, file)
                            success = True
                            break
                    
                    # N·∫øu v·∫´n kh√¥ng t√¨m th·∫•y, t√¨m file .srt m·ªõi nh·∫•t
                    if not actual_srt_file:
                        srt_files = [f for f in os.listdir(srt_folder) if f.endswith('.srt')]
                        if srt_files:
                            # L·∫•y file m·ªõi nh·∫•t
                            latest_file = max(srt_files, key=lambda x: os.path.getctime(os.path.join(srt_folder, x)))
                            actual_srt_file = os.path.join(srt_folder, latest_file)
                            success = True
                            
        except Exception as e:
            error_message = str(e)
            logging.error(f"L·ªói khi download subtitle: {e}")
        
        if success and actual_srt_file:
            # L∆∞u th√¥ng tin v√†o database v·ªõi file th·ª±c t·∫ø
            actual_filename = os.path.basename(actual_srt_file)
            srt_doc = {
                'video_url': video_url,
                'video_id': ObjectId(video_id),
                'srt_file_path': actual_srt_file,
                'srt_filename': actual_filename,
                'status': 0,  # 0: pending processing
                'created_at': datetime.utcnow(),
                'updated_at': datetime.utcnow()
            }
            
            result = mongo.db.srt_files.insert_one(srt_doc)
            
            # C·∫≠p nh·∫≠t status c·ªßa video
            mongo.db.videos.update_one(
                {'_id': ObjectId(video_id)},
                {'$set': {'status':1,'srt_status': 1, 'updated_at': datetime.utcnow()}}  # 1: SRT downloaded
            )
            
            return jsonify({
                'success': True,
                'message': 'SRT file downloaded successfully',
                'srt_id': str(result.inserted_id),
                'srt_filename': actual_filename,
                'srt_file_path': actual_srt_file
            }), 200
        else:
            return jsonify({
                'success': False,
                'error': f'Failed to download subtitle: {error_message}'
            }), 500
            
    except Exception as e:
        log_exception("crawl_video_srt", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

from elasticsearch import Elasticsearch, exceptions
import time
ES_HOST = "http://37.27.181.54:9200" # ƒê·ªãa ch·ªâ Elasticsearch
ES_INDEX_NAME = "articles"          # T√™n index b·∫°n mu·ªën l∆∞u d·ªØ li·ªáu
MODEL_NAME = 'all-distilroberta-v1' # Model d√πng ƒë·ªÉ m√£ h√≥a
from sentence_transformers import SentenceTransformer
try:
    # --- Kh·ªüi t·∫°o k·∫øt n·ªëi v√† model (ch·ªâ m·ªôt l·∫ßn) ---
    logging.info("üîå ƒêang k·∫øt n·ªëi ƒë·∫øn Elasticsearch...")
    es_connection = Elasticsearch([ES_HOST])
    if not es_connection.ping():
        raise ConnectionError(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn Elasticsearch t·∫°i {ES_HOST}")
    logging.info("   ‚úî K·∫øt n·ªëi Elasticsearch th√†nh c√¥ng!")

    logging.info(f"üß† ƒêang t·∫£i model '{MODEL_NAME}'... (c√≥ th·ªÉ m·∫•t m·ªôt l√∫c)")
    transformer_model = SentenceTransformer('all-distilroberta-v1')
    logging.info("   ‚úî T·∫£i model th√†nh c√¥ng!")
    
except exceptions.ConnectionError as e:
    logging.error(f"üî• L·ªñI K·∫æT N·ªêI ELASTICSEARCH: {e}")
except Exception as e:
    logging.error(f"üî• ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën trong qu√° tr√¨nh th·ª±c thi: {e}")
    
@main.route('/api/crawl-and-chunk-video', methods=['POST'])
def crawl_and_chunk_video():
    """
    API g·ªôp crawl SRT v√† chunk cho m·ªôt video c·ª• th·ªÉ
    """
    try:
        data = request.get_json()
        video_id = data.get('video_id')
        
        if not video_id:
            return jsonify({
                'success': False,
                'error': 'Video ID is required'
            }), 400
        
        mongo = get_mongo()
        
        # L·∫•y th√¥ng tin video
        video = mongo.db.videos.find_one({'_id': ObjectId(video_id)})
        if not video:
            return jsonify({
                'success': False,
                'error': 'Video not found'
            }), 404
        channel = mongo.db.youtube_channels.find_one({'channel_id': video['channel_id']})
        channel_url = channel['url']
        video_url = video['url']
        print(f"Processing video: {video_url}")
        
        # Ki·ªÉm tra xem ƒë√£ c√≥ SRT file ch∆∞a - n·∫øu c√≥ th√¨ x√≥a ƒë·ªÉ crawl l·∫°i
        existing_srt = mongo.db.srt_files.find_one({'video_url': video_url})
        if existing_srt:
            print(f"Found existing SRT file, deleting to re-crawl: {existing_srt['_id']}")
            # X√≥a SRT file c≈© v√† chunks li√™n quan
            mongo.db.srt_chunks.delete_many({'srt_id': existing_srt['_id']})
            mongo.db.srt_files.delete_one({'_id': existing_srt['_id']})
            
            # X√≥a file v·∫≠t l√Ω n·∫øu t·ªìn t·∫°i
            if os.path.exists(existing_srt.get('srt_file_path', '')):
                try:
                    os.remove(existing_srt['srt_file_path'])
                except Exception as e:
                    print(f"Warning: Could not delete old SRT file: {e}")
            
                # X√≥a chunks kh·ªèi Elasticsearch
                try:
                    es_delete_result = elasticsearch_service.delete_video_chunks(video_id)
                    if es_delete_result['success']:
                        print(f"‚úÖ Deleted {es_delete_result.get('deleted_count', 0)} Elasticsearch records")
                    else:
                        print(f"‚ö†Ô∏è Elasticsearch deletion warning: {es_delete_result['message']}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Elasticsearch deletion error: {str(e)}")
            
            # Reset video status v·ªÅ pending
            mongo.db.videos.update_one(
                {'_id': ObjectId(video_id)},
                {'$set': {'srt_status': 0, 'updated_at': datetime.utcnow()}}
            )
        
        # B∆Ø·ªöC 1: CRAWL SRT FILE
        print("Step 1: Crawling SRT file...")
        srt_folder = 'srt_files'
        if not os.path.exists(srt_folder):
            os.makedirs(srt_folder)
        
        # T·∫°o t√™n file unique
        srt_filename = generate_unique_filename(video_url)
        srt_file_path = os.path.join(srt_folder, srt_filename)
        
        # C·∫•u h√¨nh yt-dlp ƒë·ªÉ download subtitle
        ydl_opts = {
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': ['en'],
            'subtitlesformat': 'srt',
            'skip_download': True,
            'cookies': 'cookies.txt',
            'outtmpl': srt_file_path.replace('.srt', '.%(ext)s'),
        }
        
        srt_success = False
        srt_error_message = ""
        actual_srt_file = None
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([video_url])
                
                # T√¨m file SRT th·ª±c t·∫ø ƒë∆∞·ª£c t·∫°o
                if os.path.exists(srt_file_path):
                    actual_srt_file = srt_file_path
                    srt_success = True
                else:
                    # T√¨m file c√≥ ch·ª©a video ID
                    video_id_from_url = video_url.split('v=')[-1].split('&')[0] if 'v=' in video_url else ''
                    for file in os.listdir(srt_folder):
                        if file.endswith('.srt') and video_id_from_url in file:
                            actual_srt_file = os.path.join(srt_folder, file)
                            srt_success = True
                            break
                    
                    # N·∫øu v·∫´n kh√¥ng t√¨m th·∫•y, l·∫•y file m·ªõi nh·∫•t
                    if not actual_srt_file:
                        srt_files = [f for f in os.listdir(srt_folder) if f.endswith('.srt')]
                        if srt_files:
                            latest_file = max(srt_files, key=lambda x: os.path.getctime(os.path.join(srt_folder, x)))
                            actual_srt_file = os.path.join(srt_folder, latest_file)
                            srt_success = True
                            
        except Exception as e:
            srt_error_message = str(e)
            logging.error(f"L·ªói khi download subtitle: {e}")
        
        if not srt_success or not actual_srt_file:
            return jsonify({
                'success': False,
                'error': f'Failed to download subtitle: {srt_error_message}',
                'step': 'crawl_srt'
            }), 500
        
        # L∆∞u th√¥ng tin SRT file v√†o database
        actual_filename = os.path.basename(actual_srt_file)
        srt_doc = {
            'video_url': video_url,
            'video_id': ObjectId(video_id),
            'srt_file_path': actual_srt_file,
            'srt_filename': actual_filename,
            'status': 0,  # 0: pending processing
            'created_at': datetime.utcnow(),
            'updated_at': datetime.utcnow()
        }
        
        srt_result = mongo.db.srt_files.insert_one(srt_doc)
        srt_id = srt_result.inserted_id
        
        # B∆Ø·ªöC 2: CHUNK SRT FILE
        print("Step 2: Chunking SRT file...")
        chunks_data = process_srt_file(actual_srt_file)
        
        if not chunks_data:
            return jsonify({
                'success': False,
                'error': 'No chunks extracted from SRT file',
                'step': 'chunk_srt'
            }), 500
        
        # L∆∞u chunks v√†o MongoDB
        chunks_docs = []
        for i, chunk_info in enumerate(chunks_data):
            chunk_doc = {
                'srt_id': srt_id,
                'video_id': ObjectId(video_id),
                'video_url': video_url,
                'chunk_index': i,
                'text': chunk_info['text'],
                'time': chunk_info['time'],
                'created_at': datetime.utcnow()
            }
            chunks_docs.append(chunk_doc)
        
        # Insert t·∫•t c·∫£ chunks
        if chunks_docs:
            mongo.db.srt_chunks.insert_many(chunks_docs)
        
        # C·∫≠p nh·∫≠t status c·ªßa SRT file
        mongo.db.srt_files.update_one(
            {'_id': srt_id},
            {
                '$set': {
                    'status': 1,  # 1: processed
                    'chunks_count': len(chunks_data),
                    'updated_at': datetime.utcnow()
                }
            }
        )
        
        # B∆Ø·ªöC 3: ELASTICSEARCH VECTOR INDEXING
        es_result = []
        print("Step 3: Elasticsearch vector indexing...")
        try:
            video_info = {
                'video_id': video_id,
                'title': video.get('title', ''),
                'channel_name': video.get('channel_name', ''),
                'url': video.get('url', ''),
                'channel_url': video.get('channel_url', '')  # Th√™m channel URL
            }
            delete_query = {
                "query": {
                    "term": {
                        "url": video.get('url', ''),
                    }
                }
            }
            response = es_connection.delete_by_query(
                index=ES_INDEX_NAME,
                body=delete_query
            )
            deleted_count = response.get('deleted', 0)
            if deleted_count > 0:
                print(f"‚úÖ ƒê√£ x√≥a th√†nh c√¥ng {deleted_count} document.")
            else:
                print("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y document n√†o kh·ªõp ƒë·ªÉ x√≥a. H√£y ki·ªÉm tra l·∫°i gi√° tr·ªã URL v√† c√¢u query.")
            for data in chunks_data:
                vector = transformer_model.encode(data['text']).tolist()
               
                # 2. Chu·∫©n b·ªã document ƒë·ªÉ index
                document = {
                    'url': video.get('url', ''),
                    'origin_content': data['text'],
                    'vector': vector,
                    'time': int(time.time()),
                    'url_channel': channel_url,
                }
                # 3. Index document v√†o Elasticsearch
                logging.info(f"   - Chunk {i+1}/{len(chunks_data)}: ƒêang index v√†o '{ES_INDEX_NAME}'...")
                response = es_connection.index(index=ES_INDEX_NAME, body=document)
                response_dict = dict(response)
                pretty_response_str = json.dumps(response_dict, indent=2, ensure_ascii=False)
                print("pretty_response_str",pretty_response_str)
                logging.info(f"   ‚úî Chunk {i+1} ƒë√£ ƒë∆∞·ª£c index th√†nh c√¥ng v·ªõi ID:")
                es_result.append(pretty_response_str)
            print("data",chunks_data, video_info)
        except Exception as e:
            print(f"‚ùå Elasticsearch indexing error: {str(e)}")
            import traceback
            traceback.print_exc()
            # es_result = {
            #     'success': False,
            #     'message': f'Elasticsearch indexing error: {str(e)}',
            #     'indexed_count': 0
            # }
        
        # B∆Ø·ªöC 4: C·∫¨P NH·∫¨T STATUS VIDEO
        print("Step 4: Updating video status...")
        mongo.db.videos.update_one(
            {'_id': ObjectId(video_id)},
            {'$set': {'status':1,'srt_status': 1, 'updated_at': datetime.utcnow()}}  # 1: SRT processed
        )
        
        return jsonify({
            'success': True,
            'message': f'Successfully crawled and chunked video with {len(chunks_data)} chunks',
            'srt_id': str(srt_id),
            'srt_filename': actual_filename,
            'srt_file_path': actual_srt_file,
            'chunks_count': len(chunks_data),
            'video_status': 1,
            'elasticsearch': es_result
        }), 200
        
    except Exception as e:
        log_exception("crawl_and_chunk_video", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/index-content', methods=['POST'])
def index_content():
    """
    API ƒë·ªÉ index content th√†nh chunks v√† l∆∞u v√†o Elasticsearch
    Nh·∫≠n v√†o: url_channel, url, content
    """
    try:
        data = request.get_json()
        url_channel = data.get('url_channel')
        url = data.get('url')
        content = data.get('content')
        
        if not all([url_channel, url, content]):
            return jsonify({
                'success': False,
                'error': 'url_channel, url, and content are required'
            }), 400
        
        print(f"Processing content for URL: {url}")
        
        # B∆Ø·ªöC 1: KI·ªÇM TRA V√Ä X√ìA D·ªÆ LI·ªÜU C≈® (n·∫øu c√≥)
        print("Step 1: Checking and deleting existing data...")
        try:
            delete_query = {
                "query": {
                    "term": {
                        "url": url
                    }
                }
            }
            response = es_connection.delete_by_query(
                index=ES_INDEX_NAME,
                body=delete_query
            )
            deleted_count = response.get('deleted', 0)
            if deleted_count > 0:
                print(f"‚úÖ ƒê√£ x√≥a th√†nh c√¥ng {deleted_count} document c≈©.")
            else:
                print("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y document n√†o kh·ªõp ƒë·ªÉ x√≥a.")
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi x√≥a d·ªØ li·ªáu c≈©: {str(e)}")
        
        # B∆Ø·ªöC 2: CHIA CONTENT TH√ÄNH CHUNKS
        print("Step 2: Splitting content into chunks...")
        chunks_data = split_content_into_chunks(content)
        
        if not chunks_data:
            return jsonify({
                'success': False,
                'error': 'No chunks extracted from content',
                'step': 'chunk_content'
            }), 500
        
        print(f"Created {len(chunks_data)} chunks from content")
        
        # B∆Ø·ªöC 3: M√É H√ìA V√Ä INDEX V√ÄO ELASTICSEARCH
        print("Step 3: Encoding and indexing to Elasticsearch...")
        indexed_count = 0
        es_errors = []
        
        try:
            for i, chunk_text in enumerate(chunks_data):
                try:
                    # M√£ h√≥a chunk th√†nh vector
                    vector = transformer_model.encode(chunk_text).tolist()
                    
                    # Chu·∫©n b·ªã document ƒë·ªÉ index
                    document = {
                        'url': url,
                        'url_channel': url_channel,
                        'origin_content': chunk_text,
                        'vector': vector,
                        'time': int(time.time()),
                        'chunk_index': i
                    }
                    
                    # Index document v√†o Elasticsearch
                    response = es_connection.index(index=ES_INDEX_NAME, body=document)
                    indexed_count += 1
                    print(f"   ‚úî Chunk {i+1}/{len(chunks_data)} indexed successfully")
                    
                except Exception as e:
                    error_msg = f"Error indexing chunk {i+1}: {str(e)}"
                    print(f"   ‚ùå {error_msg}")
                    es_errors.append(error_msg)
                    
        except Exception as e:
            print(f"‚ùå Elasticsearch indexing error: {str(e)}")
            import traceback
            traceback.print_exc()
        
        # B∆Ø·ªöC 4: TR·∫¢ V·ªÄ K·∫æT QU·∫¢
        result = {
            'success': True,
            'message': f'Successfully indexed {indexed_count} chunks from content',
            'total_chunks': len(chunks_data),
            'indexed_count': indexed_count,
            'url': url,
            'url_channel': url_channel
        }
        
        if es_errors:
            result['warnings'] = es_errors
            result['message'] += f' (with {len(es_errors)} errors)'
        
        return jsonify(result), 200
        
    except Exception as e:
        log_exception("index_content", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def split_content_into_chunks(content, max_chunk_size=500, overlap=50):
    """
    Chia content th√†nh c√°c chunks ph√π h·ª£p
    """
    if not content or not content.strip():
        return []
    
    # L√†m s·∫°ch content
    content = content.strip()
    
    # N·∫øu content ng·∫Øn h∆°n max_chunk_size, tr·∫£ v·ªÅ 1 chunk
    if len(content) <= max_chunk_size:
        return [content]
    
    chunks = []
    start = 0
    
    while start < len(content):
        # X√°c ƒë·ªãnh v·ªã tr√≠ k·∫øt th√∫c chunk
        end = start + max_chunk_size
        
        if end >= len(content):
            # Chunk cu·ªëi c√πng
            chunks.append(content[start:].strip())
            break
        
        # T√¨m v·ªã tr√≠ t·ªët ƒë·ªÉ c·∫Øt (∆∞u ti√™n d·∫•u c√¢u, xu·ªëng d√≤ng)
        cut_positions = [
            content.rfind('.', start, end),
            content.rfind('!', start, end),
            content.rfind('?', start, end),
            content.rfind('\n', start, end),
            content.rfind(' ', start, end)
        ]
        
        # Ch·ªçn v·ªã tr√≠ c·∫Øt t·ªët nh·∫•t
        best_cut = max([pos for pos in cut_positions if pos > start + max_chunk_size // 2])
        
        if best_cut > start:
            end = best_cut + 1
        
        chunk = content[start:end].strip()
        if chunk:
            chunks.append(chunk)
        
        # T√≠nh to√°n v·ªã tr√≠ b·∫Øt ƒë·∫ßu chunk ti·∫øp theo (c√≥ overlap)
        start = max(start + 1, end - overlap)
    
    return chunks

@main.route('/api/process-video-srt', methods=['POST'])
def process_video_srt():
    """
    API ƒë·ªÉ x·ª≠ l√Ω SRT cho m·ªôt video c·ª• th·ªÉ
    """
    try:
        data = request.get_json()
        video_id = data.get('video_id')
        
        if not video_id:
            return jsonify({
                'success': False,
                'error': 'Video ID is required'
            }), 400
        
        mongo = get_mongo()
        
        # L·∫•y th√¥ng tin video
        video = mongo.db.videos.find_one({'_id': ObjectId(video_id)})
        if not video:
            return jsonify({
                'success': False,
                'error': 'Video not found'
            }), 404
        
        # L·∫•y SRT files c·ªßa video n√†y
        srt_files = list(mongo.db.srt_files.find({'video_url': video['url'], 'status': 0}))
        
        if not srt_files:
            return jsonify({
                'success': False,
                'error': 'No pending SRT files found for this video'
            }), 404
        
        total_chunks = 0
        processed_files = 0
        
        for srt_file in srt_files:
            srt_file_path = srt_file['srt_file_path']
            
            # Ki·ªÉm tra file t·ªìn t·∫°i
            if not os.path.exists(srt_file_path):
                continue
            
            # X·ª≠ l√Ω file SRT
            chunks_data = process_srt_file(srt_file_path)
            
            if not chunks_data:
                continue
            
            # L∆∞u chunks v√†o MongoDB
            chunks_docs = []
            for i, chunk_info in enumerate(chunks_data):
                chunk_doc = {
                    'srt_id': srt_file['_id'],
                    'video_id': ObjectId(video_id),
                    'video_url': video['url'],
                    'chunk_index': i,
                    'text': chunk_info['text'],
                    'time': chunk_info['time'],
                    'created_at': datetime.utcnow()
                }
                chunks_docs.append(chunk_doc)
            
            # Insert t·∫•t c·∫£ chunks
            if chunks_docs:
                mongo.db.srt_chunks.insert_many(chunks_docs)
                total_chunks += len(chunks_data)
            
            # C·∫≠p nh·∫≠t status c·ªßa SRT file
            mongo.db.srt_files.update_one(
                {'_id': srt_file['_id']},
                {
                    '$set': {
                        'status': 1,  # 1: processed
                        'chunks_count': len(chunks_data),
                        'updated_at': datetime.utcnow()
                    }
                }
            )
            processed_files += 1
        
        # C·∫≠p nh·∫≠t status c·ªßa video
        mongo.db.videos.update_one(
            {'_id': ObjectId(video_id)},
            {'$set': {'srt_status': 2, 'updated_at': datetime.utcnow()}}  # 2: SRT processed
        )
        
        return jsonify({
            'success': True,
            'message': f'Successfully processed {processed_files} SRT files with {total_chunks} chunks',
            'processed_files': processed_files,
            'chunks_count': total_chunks
        }), 200
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==============================================================================
# ELASTICSEARCH APIs
# ==============================================================================

@main.route('/api/search', methods=['GET'])
def search_videos():
    """
    API t√¨m ki·∫øm semantic trong Elasticsearch v·ªõi vector embeddings
    """
    try:
        # Get search parameters
        query = request.args.get('q', '').strip()
        video_id = request.args.get('video_id', None)
        size = int(request.args.get('size', 10))
        from_ = int(request.args.get('from', 0))
        
        if not query:
            return jsonify({
                'success': False,
                'error': 'Query parameter "q" is required'
            }), 400
        
        # Perform semantic search
        search_result = elasticsearch_service.search_chunks(
            query=query,
            video_id=video_id,
            size=size,
            from_=from_
        )
        
        if search_result['success']:
            return jsonify({
                'success': True,
                'query': query,
                'results': search_result['results'],
                'total': search_result['total'],
                'took': search_result['took'],
                'message': f"Found {len(search_result['results'])} results"
            }), 200
        else:
            return jsonify({
                'success': False,
                'error': search_result['message']
            }), 500
            
    except Exception as e:
        logging.error(f"Search API error: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'Search failed: {str(e)}'
        }), 500

@main.route('/api/elasticsearch/stats', methods=['GET'])
def get_elasticsearch_stats():
    """
    API l·∫•y th·ªëng k√™ Elasticsearch index
    """
    try:
        stats = elasticsearch_service.get_index_stats()
        
        if stats['success']:
            return jsonify({
                'success': True,
                'stats': stats
            }), 200
        else:
            return jsonify({
                'success': False,
                'error': stats['message']
            }), 500
            
    except Exception as e:
        logging.error(f"Elasticsearch stats API error: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'Failed to get stats: {str(e)}'
        }), 500

@main.route('/api/elasticsearch/health', methods=['GET'])
def get_elasticsearch_health():
    """
    API ki·ªÉm tra health c·ªßa Elasticsearch v√† model
    """
    try:
        health = elasticsearch_service.health_check()
        
        return jsonify({
            'success': True,
            'health': health
        }), 200
        
    except Exception as e:
        logging.error(f"Elasticsearch health API error: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'Health check failed: {str(e)}'
        }), 500

@main.route('/api/elasticsearch/delete-video', methods=['POST'])
def delete_video_from_elasticsearch():
    """
    API x√≥a t·∫•t c·∫£ chunks c·ªßa m·ªôt video kh·ªèi Elasticsearch
    """
    try:
        data = request.get_json()
        video_id = data.get('video_id') if data else None
        
        if not video_id:
            return jsonify({
                'success': False,
                'error': 'video_id is required'
            }), 400
        
        # Delete video chunks from Elasticsearch
        delete_result = elasticsearch_service.delete_video_chunks(video_id)
        
        if delete_result['success']:
            return jsonify({
                'success': True,
                'message': delete_result['message'],
                'deleted_count': delete_result.get('deleted_count', 0)
            }), 200
        else:
            return jsonify({
                'success': False,
                'error': delete_result['message']
            }), 500
            
    except Exception as e:
        logging.error(f"Elasticsearch delete API error: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'Delete failed: {str(e)}'
        }), 500

@main.route('/api/cleanup-video-data', methods=['POST'])
def cleanup_video_data():
    """
    API x√≥a to√†n b·ªô d·ªØ li·ªáu c≈© c·ªßa video: SRT files, chunks, Elasticsearch records
    """
    try:
        data = request.get_json()
        video_id = data.get('video_id') if data else None
        
        if not video_id:
            return jsonify({
                'success': False,
                'error': 'video_id is required'
            }), 400
        
        mongo = get_mongo()
        cleanup_results = {
            'srt_files_deleted': 0,
            'chunks_deleted': 0,
            'elasticsearch_deleted': 0,
            'errors': []
        }
        
        # B∆Ø·ªöC 1: X√ìA SRT FILES
        try:
            print(f"üóëÔ∏è Deleting SRT files for video: {video_id}")
            srt_files = mongo.db.srt_files.find({'video_id': ObjectId(video_id)})
            
            for srt_file in srt_files:
                # X√≥a file v·∫≠t l√Ω
                srt_file_path = srt_file.get('file_path')
                if srt_file_path and os.path.exists(srt_file_path):
                    try:
                        os.remove(srt_file_path)
                        print(f"‚úÖ Deleted SRT file: {srt_file_path}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è Failed to delete SRT file {srt_file_path}: {str(e)}")
                        cleanup_results['errors'].append(f"SRT file deletion: {str(e)}")
                
                # X√≥a record trong MongoDB
                mongo.db.srt_files.delete_one({'_id': srt_file['_id']})
                cleanup_results['srt_files_deleted'] += 1
                
        except Exception as e:
            print(f"‚ùå Error deleting SRT files: {str(e)}")
            cleanup_results['errors'].append(f"SRT files: {str(e)}")
        
        # B∆Ø·ªöC 2: X√ìA CHUNKS
        try:
            print(f"üóëÔ∏è Deleting chunks for video: {video_id}")
            chunks_result = mongo.db.chunks.delete_many({'video_id': ObjectId(video_id)})
            cleanup_results['chunks_deleted'] = chunks_result.deleted_count
            print(f"‚úÖ Deleted {chunks_result.deleted_count} chunks")
            
        except Exception as e:
            print(f"‚ùå Error deleting chunks: {str(e)}")
            cleanup_results['errors'].append(f"Chunks: {str(e)}")
        
        # B∆Ø·ªöC 3: X√ìA ELASTICSEARCH RECORDS
        try:
            print(f"üóëÔ∏è Deleting Elasticsearch records for video: {video_id}")
            es_delete_result = elasticsearch_service.delete_video_chunks(video_id)
            
            if es_delete_result['success']:
                cleanup_results['elasticsearch_deleted'] = es_delete_result.get('deleted_count', 0)
                print(f"‚úÖ Deleted {cleanup_results['elasticsearch_deleted']} Elasticsearch records")
            else:
                print(f"‚ö†Ô∏è Elasticsearch deletion warning: {es_delete_result['message']}")
                cleanup_results['errors'].append(f"Elasticsearch: {es_delete_result['message']}")
                
        except Exception as e:
            print(f"‚ùå Error deleting Elasticsearch records: {str(e)}")
            cleanup_results['errors'].append(f"Elasticsearch: {str(e)}")
        
        # B∆Ø·ªöC 4: RESET VIDEO STATUS
        try:
            print(f"üîÑ Resetting video status for: {video_id}")
            mongo.db.videos.update_one(
                {'_id': ObjectId(video_id)},
                {
                    '$set': {
                        'srt_status': 0,  # 0: not processed
                        'status': 0,      # 0: not processed
                        'updated_at': datetime.utcnow()
                    }
                }
            )
            print(f"‚úÖ Reset video status")
            
        except Exception as e:
            print(f"‚ùå Error resetting video status: {str(e)}")
            cleanup_results['errors'].append(f"Video status: {str(e)}")
        
        # T·ªïng k·∫øt
        total_deleted = (cleanup_results['srt_files_deleted'] + 
                        cleanup_results['chunks_deleted'] + 
                        cleanup_results['elasticsearch_deleted'])
        
        if cleanup_results['errors']:
            return jsonify({
                'success': True,
                'message': f'Cleanup completed with {len(cleanup_results["errors"])} warnings',
                'results': cleanup_results,
                'total_deleted': total_deleted,
                'warnings': cleanup_results['errors']
            }), 200
        else:
            return jsonify({
                'success': True,
                'message': f'Successfully cleaned up all data for video',
                'results': cleanup_results,
                'total_deleted': total_deleted
            }), 200
            
    except Exception as e:
        logging.error(f"Cleanup API error: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'Cleanup failed: {str(e)}'
        }), 500

# ==============================================================================
# REQUESTS COLLECTION API
# ==============================================================================

@main.route('/api/requests', methods=['POST'])
def save_request():
    """
    API nh·∫≠n POST raw JSON v√† l∆∞u v√†o collection requests
    
    Y√™u c·∫ßu:
    - Secret key ph·∫£i ƒë∆∞·ª£c truy·ªÅn qua param 'secret_key' ho·∫∑c header 'X-Secret-Key'
    - JSON body ch·ª©a d·ªØ li·ªáu c·∫ßn l∆∞u
    
    X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho type: "event_match_end" - t·ª± ƒë·ªông generate article
    
    C√°ch s·ª≠ d·ª•ng:
    POST /api/requests?secret_key=your_secret_key
    ho·∫∑c
    POST /api/requests
    Header: X-Secret-Key: your_secret_key
    Body: JSON data
    """
    try:
        # Check secret key first (supports query param, header aliases, trims, and config/env)
        provided_secret = (
            request.args.get('secret_key')
            or request.args.get('SECRET_KEY')
            or request.headers.get('X-Secret-Key')
            or request.headers.get('X-SECRET-KEY')
        )
        provided_secret = (provided_secret or '').strip()

        # Prefer Flask config, fallback to env
        expected_secret = "7b81b8c09cfab64cb3f4804208d2ad97dcd95b99d7fd0a2bb87cf207ddb54dd8"
        
        # Debug logging for key sources
        logging.info(f"Secret key sources debug:")
        logging.info(f"  - Query param 'secret_key': {bool(request.args.get('secret_key'))}")
        logging.info(f"  - Query param 'SECRET_KEY': {bool(request.args.get('SECRET_KEY'))}")
        logging.info(f"  - Header 'X-Secret-Key': {bool(request.headers.get('X-Secret-Key'))}")
        logging.info(f"  - Header 'X-SECRET-KEY': {bool(request.headers.get('X-SECRET-KEY'))}")
        logging.info(f"  - Flask config SECRET_KEY: {bool(current_app.config.get('SECRET_KEY'))}")
        logging.info(f"  - Env SECRET_KEY: {bool(os.getenv('SECRET_KEY'))}")

        if not expected_secret:
            logging.error("SECRET_KEY not configured (missing in app config and env)")
            return jsonify({'success': False, 'error': 'Server configuration error'}), 500

        if not provided_secret:
            logging.warning("API request missing secret key (no query/header provided)")
            return jsonify({'success': False, 'error': 'Secret key required'}), 401

        # Log partial keys for debugging (first 4 chars + last 4 chars for security)
        def mask_key(key):
            if len(key) <= 8:
                return "*" * len(key)
            return f"{key[:4]}...{key[-4:]}"
        
        logging.info(f"Secret key debug:")
        logging.info(f"  - Provided: '{mask_key(provided_secret)}' (len={len(provided_secret)})")
        logging.info(f"  - Expected: '{mask_key(expected_secret)}' (len={len(expected_secret)})")
        logging.info(f"  - Match: {provided_secret == expected_secret}")

        if provided_secret != expected_secret:
            logging.warning("Invalid secret key provided (mismatch)")
            return jsonify({'success': False, 'error': 'Invalid secret key'}), 401

        logging.info("Secret key validation successful")
        
        # L·∫•y raw JSON data t·ª´ request
        raw_data = request.get_json()
        
        if not raw_data:
            return jsonify({
                'success': False,
                'error': 'No JSON data provided'
            }), 400
        
        mongo = get_mongo()
        
        # T·∫°o document ƒë·ªÉ l∆∞u v√†o collection requests
        # Ch·ªâ l∆∞u JSON body + timestamp
        request_doc = {
            **raw_data,  # L∆∞u to√†n b·ªô JSON data tr·ª±c ti·∫øp
            'created_at': datetime.utcnow()
        }
        
        # L∆∞u v√†o MongoDB
        result = mongo.db.requests.insert_one(request_doc)
        
        # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho event_match_end
        if raw_data.get('type') == 'event_match_end':
            try:
                fixture_id = raw_data.get('fixture_id')
                if not fixture_id:
                    logging.warning("‚ö†Ô∏è event_match_end request missing fixture_id")
                    request_doc['article_generated'] = False
                    request_doc['generation_error'] = 'Missing fixture_id'
                else:
                    logging.info(f"üéØ Processing event_match_end for fixture_id: {fixture_id}")
                    
                    # Query t·∫•t c·∫£ requests c√≥ c√πng fixture_id
                    related_requests = list(mongo.db.requests.find({
                        'fixture_id': fixture_id,
                        'type': {'$ne': 'event_match_end'}  # Lo·∫°i tr·ª´ ch√≠nh request n√†y
                    }))
                    
                    logging.info(f"üìä Found {len(related_requests)} related requests for fixture_id: {fixture_id}")
                    
                    if related_requests:
                        # Kh·ªüi t·∫°o thread ri√™ng ƒë·ªÉ x·ª≠ l√Ω t·∫°o b√†i vi·∫øt
                        thread = threading.Thread(
                            target=process_article_generation_async,
                            args=(fixture_id, related_requests, str(result.inserted_id)),
                            name=f"ArticleGen-{fixture_id}"
                        )
                        thread.daemon = True  # Thread s·∫Ω t·ª± ƒë·ªông k·∫øt th√∫c khi main thread k·∫øt th√∫c
                        thread.start()
                        
                        logging.info(f"üöÄ Started async article generation thread for fixture_id: {fixture_id}")
                        logging.info(f"üìã Thread name: {thread.name}")
                        logging.info(f"‚è∞ Article generation will start in 20 seconds...")
                        
                        # Set initial status - s·∫Ω ƒë∆∞·ª£c update b·ªüi thread
                        request_doc['article_generation_status'] = 'processing'
                        request_doc['article_generation_started_at'] = datetime.utcnow()
                        request_doc['article_generated'] = False  # S·∫Ω ƒë∆∞·ª£c update khi ho√†n th√†nh
                        
                    else:
                        logging.warning(f"‚ö†Ô∏è No related requests found for fixture_id: {fixture_id}")
                        request_doc['article_generated'] = False
                        request_doc['generation_error'] = 'No related requests found'
                        
            except Exception as e:
                logging.error(f"‚ùå Error setting up event_match_end processing: {str(e)}")
                logging.error(f"üìã Traceback: {traceback.format_exc()}")
                request_doc['article_generated'] = False
                request_doc['generation_error'] = str(e)
        
        return jsonify({
            'success': True,
            'message': 'Request saved successfully',
            'request_id': str(result.inserted_id),
            'created_at': request_doc['created_at'].isoformat(),
            'article_generated': request_doc.get('article_generated', False),
            'generated_article_id': request_doc.get('generated_article_id'),
            'generation_error': request_doc.get('generation_error'),
            'article_generation_status': request_doc.get('article_generation_status', 'not_applicable'),
            'article_generation_started_at': request_doc.get('article_generation_started_at').isoformat() if request_doc.get('article_generation_started_at') else None
        }), 201
        
    except Exception as e:
        log_exception("save_request", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/requests', methods=['GET'])
def get_requests():
    """
    API l·∫•y danh s√°ch requests t·ª´ collection requests
    """
    try:
        mongo = get_mongo()
        
        # L·∫•y parameters t·ª´ query
        limit = int(request.args.get('limit', 50))
        skip = int(request.args.get('skip', 0))
        
        # Build query - c√≥ th·ªÉ filter theo b·∫•t k·ª≥ field n√†o trong JSON body
        query = {}
        for key, value in request.args.items():
            if key not in ['limit', 'skip']:
                query[key] = value
        
        # Query requests, sorted by newest first
        requests = list(mongo.db.requests.find(query)
                       .sort('created_at', -1)
                       .skip(skip)
                       .limit(limit))
        
        # Convert ObjectId to string for JSON serialization
        for req in requests:
            req['_id'] = str(req['_id'])
            if 'created_at' in req:
                req['created_at'] = req['created_at'].isoformat() if hasattr(req['created_at'], 'isoformat') else str(req['created_at'])
        
        # Get total count
        total_count = mongo.db.requests.count_documents(query)
        
        return jsonify({
            'success': True,
            'requests': requests,
            'total_count': total_count,
            'limit': limit,
            'skip': skip
        }), 200
        
    except Exception as e:
        log_exception("get_requests", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/requests/<request_id>', methods=['GET'])
def get_request(request_id):
    """
    API l·∫•y chi ti·∫øt m·ªôt request c·ª• th·ªÉ
    """
    try:
        mongo = get_mongo()
        
        request_doc = mongo.db.requests.find_one({'_id': ObjectId(request_id)})
        if not request_doc:
            return jsonify({
                'success': False,
                'error': 'Request not found'
            }), 404
        
        # Convert ObjectId to string for JSON serialization
        request_doc = serialize_document(request_doc)
        
        return jsonify({
            'success': True,
            'request': request_doc
        }), 200
        
    except Exception as e:
        log_exception("get_request", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/requests/<request_id>', methods=['DELETE'])
def delete_request(request_id):
    """
    API x√≥a m·ªôt request c·ª• th·ªÉ
    """
    try:
        mongo = get_mongo()
        
        result = mongo.db.requests.delete_one({'_id': ObjectId(request_id)})
        
        if result.deleted_count == 0:
            return jsonify({
                'success': False,
                'error': 'Request not found'
            }), 404
        
        return jsonify({
            'success': True,
            'message': 'Request deleted successfully'
        }), 200
        
    except Exception as e:
        log_exception("delete_request", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==============================================================================
# GENERATED ARTICLES API
# ==============================================================================

@main.route('/api/generated-articles', methods=['GET'])
def get_generated_articles():
    """
    API l·∫•y danh s√°ch generated articles
    """
    try:
        mongo = get_mongo()
        
        # L·∫•y parameters t·ª´ query
        limit = int(request.args.get('limit', 50))
        skip = int(request.args.get('skip', 0))
        fixture_id = request.args.get('fixture_id')
        
        # Build query
        query = {}
        if fixture_id:
            query['fixture_id'] = fixture_id
        
        # Query generated articles, sorted by newest first
        articles = list(mongo.db.generated_articles.find(query)
                       .sort('generated_at', -1)
                       .skip(skip)
                       .limit(limit))
        
        # Convert ObjectId to string for JSON serialization
        for article in articles:
            article['_id'] = str(article['_id'])
            if 'generated_at' in article:
                article['generated_at'] = article['generated_at'].isoformat() if hasattr(article['generated_at'], 'isoformat') else str(article['generated_at'])
            if 'created_at' in article:
                article['created_at'] = article['created_at'].isoformat() if hasattr(article['created_at'], 'isoformat') else str(article['created_at'])
        
        # Get total count
        total_count = mongo.db.generated_articles.count_documents(query)
        
        return jsonify({
            'success': True,
            'articles': articles,
            'total_count': total_count,
            'limit': limit,
            'skip': skip
        }), 200
        
    except Exception as e:
        log_exception("get_generated_articles", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@main.route('/api/generated-articles/<article_id>', methods=['GET'])
def get_generated_article(article_id):
    """
    API l·∫•y chi ti·∫øt m·ªôt generated article
    """
    try:
        mongo = get_mongo()
        
        article = mongo.db.generated_articles.find_one({'_id': ObjectId(article_id)})
        if not article:
            return jsonify({
                'success': False,
                'error': 'Generated article not found'
            }), 404
        
        # Convert ObjectId to string for JSON serialization
        article = serialize_document(article)
        
        return jsonify({
            'success': True,
            'article': article
        }), 200
        
    except Exception as e:
        log_exception("get_generated_article", e)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500
